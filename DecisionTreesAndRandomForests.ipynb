{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 6 Solution\n",
    "\n",
    "##### Questions to julian.stastny@fu-berlin.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.347720Z",
     "start_time": "2018-11-29T11:28:47.572823Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Classifier_base import Classifier\n",
    "from math import floor\n",
    "from LinearRegression import OneVsOne, LeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.406520Z",
     "start_time": "2018-11-29T11:28:48.349530Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('Data/spambase.data', header=None))\n",
    "\n",
    "X = data[:,:-1] # features\n",
    "y = data[:,-1] # Last column is label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.414587Z",
     "start_time": "2018-11-29T11:28:48.408590Z"
    }
   },
   "outputs": [],
   "source": [
    "# We binarize the features by asking whether they are above average\n",
    "\n",
    "# We take the averages of the positive class and the negative class of the training set\n",
    "averages_pos = np.mean(X_train[y_train==1], axis=0)\n",
    "averages_neg = np.mean(X_train[y_train==0], axis=0)\n",
    "\n",
    "average_of_averages = (averages_pos + averages_neg)/2 \n",
    "# Due to class imbalance, this is not the same as just taking the average of the full training set\n",
    "\n",
    "X_train_avg = X_train > average_of_averages\n",
    "X_test_avg = X_test > average_of_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.430198Z",
     "start_time": "2018-11-29T11:28:48.419121Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree(Classifier):\n",
    "\n",
    "    def fit(self, X, y, max_depth):\n",
    "        self.num_features = len(X.T)\n",
    "        self.size_tree = 2**max_depth - 1\n",
    "        self.size_array_for_tree = 2**(max_depth+1) - 1\n",
    "        self.feature_tree = np.ones((self.size_array_for_tree), dtype=int) * (-1)\n",
    "        self.prob_tree = np.ones((self.size_array_for_tree*2)) * (-1)\n",
    "        self.split_nodes(X, y, 0)\n",
    "        return self.feature_tree, self.prob_tree\n",
    "    \n",
    "    def predict(self, feature_tree, prob_tree, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            array_position = 0\n",
    "            node = feature_tree[array_position]\n",
    "            while feature_tree[self.left(array_position)] != -1 or feature_tree[self.right(array_position)] != -1:\n",
    "                if x[node]:\n",
    "                    array_position = self.right(array_position)\n",
    "                else:\n",
    "                    array_position = self.left(array_position)\n",
    "                prediction = prob_tree[array_position]\n",
    "                node = feature_tree[array_position]\n",
    "            predictions += [prediction]\n",
    "        return predictions\n",
    "    \n",
    "    def split_nodes(self, X, y, node_id):\n",
    "        \n",
    "        if node_id >= self.size_tree: # Abort if parent node is a leaf\n",
    "            return\n",
    "        \n",
    "        expected_entropies = np.ones(self.num_features) * np.inf # initialize to inf to find true min later\n",
    "        probs_left = np.empty(self.num_features)\n",
    "        probs_right = np.empty(self.num_features)\n",
    "        \n",
    "        for i, feature in enumerate(X.T):\n",
    "            if np.sum(X[feature]) == 0 or np.sum(X[np.invert(feature)]) == 0:\n",
    "                # If one child would get all data points, we don't want to split that way\n",
    "                continue \n",
    "            e_h, prob_left, prob_right = self.weighted_children_entropy(feature, y)\n",
    "            expected_entropies[i] = e_h\n",
    "            probs_left[i] = prob_left\n",
    "            probs_right[i] = prob_right\n",
    "            \n",
    "        min_e_h = np.argmin(expected_entropies)\n",
    "        \n",
    "        right = X[:,min_e_h]\n",
    "        left = np.invert(right)\n",
    "        \n",
    "        self.feature_tree[node_id] = min_e_h\n",
    "        self.prob_tree[self.left(node_id)] = probs_left[min_e_h]\n",
    "        self.prob_tree[self.right(node_id)] = probs_right[min_e_h]\n",
    "        \n",
    "        if len(y[right]) == 0 or len(y[left]) == 0:\n",
    "            return\n",
    "        # recursive calls\n",
    "        self.split_nodes(X[left], y[left], self.left(node_id))\n",
    "        self.split_nodes(X[right], y[right], self.right(node_id))\n",
    "        \n",
    "    def entropy(self, p):\n",
    "        if p == 1 or p == 0: \n",
    "            # The entropy is zero if one event is certain\n",
    "            return 0\n",
    "        return - (p * np.log(p) + (1-p) * np.log((1-p)))\n",
    "    \n",
    "    def weighted_children_entropy(self, feature, y):\n",
    "        num_datapoints = len(feature)\n",
    "        weight_right = (feature == True).sum()/num_datapoints\n",
    "        weight_left = 1 - weight_right\n",
    "        p = np.sum(y[feature])/len(y[feature]) \n",
    "        q = np.sum(y[np.invert(feature)])/len(y[np.invert(feature)])\n",
    "        entropy_right = weight_right * self.entropy(p)\n",
    "        entropy_left = weight_left * self.entropy(q)\n",
    "        return entropy_right + entropy_left, q, p\n",
    "    \n",
    "    def left(self, node_id):\n",
    "        return 2 * node_id + 1\n",
    "    \n",
    "    def right(self, node_id):\n",
    "        return 2 * node_id + 2\n",
    "    \n",
    "    def parent(self, node_id):\n",
    "        return floor((node_id - 1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:49.036054Z",
     "start_time": "2018-11-29T11:28:49.028396Z"
    }
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:15.240136Z",
     "start_time": "2018-11-29T11:29:14.947907Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_tree, prob_tree = decision_tree.fit(X_train_avg, y_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:15.775171Z",
     "start_time": "2018-11-29T11:29:15.728002Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = decision_tree.predict(feature_tree, prob_tree, X_test_avg)\n",
    "estimates = (np.array(predictions) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:16.010062Z",
     "start_time": "2018-11-29T11:29:15.995646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052997393570807"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.accuracy(y_test, estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:29:14.768681Z",
     "start_time": "2018-11-28T14:29:14.758714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[668,  29],\n",
       "       [ 80, 374]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.confusion_matrix(y_test, estimates).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:29:14.781004Z",
     "start_time": "2018-11-28T14:29:14.771015Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForest(Classifier):\n",
    "    \n",
    "    def __init__(self):\n",
    "        decision_tree = DecisionTree()\n",
    "    \n",
    "    def fit(self, X, y, num_trees, num_samples_per_tree, depth):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        num_samples = len(X)\n",
    "        num_features = len(X.T)\n",
    "        feature_trees = []\n",
    "        prob_trees = []\n",
    "        features = []\n",
    "        for i in range(num_trees):\n",
    "            random_samples = np.random.randint(0, high=num_samples, size=num_samples_per_tree)\n",
    "            X = self.X[random_samples]\n",
    "            y = self.y[random_samples]\n",
    "            random_features = np.random.randint(0, high=num_features, size=depth*2)\n",
    "            X = X[:,random_features]\n",
    "            feature_tree, prob_tree = decision_tree.fit(X, y, depth)\n",
    "            feature_trees += [feature_tree]\n",
    "            prob_trees += [prob_tree]\n",
    "            features += [random_features]\n",
    "        return feature_trees, prob_trees, features\n",
    "    \n",
    "    def predict(self, feature_trees, prob_trees, X):\n",
    "        predictions = np.empty((len(feature_trees), len(X)))\n",
    "        for i, (feature_tree, prob_tree, feature_set) in enumerate(zip(feature_trees, prob_trees, features)):\n",
    "            predictions[i] = decision_tree.predict(feature_tree, prob_tree, X[:,feature_set])\n",
    "        averaged_predictions = np.mean(predictions, axis=0)\n",
    "        return averaged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:29:17.345169Z",
     "start_time": "2018-11-28T14:29:14.782736Z"
    }
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForest()\n",
    "feature_trees, prob_trees, features = random_forest.fit(X_train_avg, y_train, 50, 1000, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:29:17.816404Z",
     "start_time": "2018-11-28T14:29:17.351254Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = random_forest.predict(feature_trees, prob_trees, X_test_avg)\n",
    "estimates = (np.array(predictions) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:29:17.824949Z",
     "start_time": "2018-11-28T14:29:17.818344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9209383145091226"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.accuracy(y_test, estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:29:17.837039Z",
     "start_time": "2018-11-28T14:29:17.827848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[684.,  13.],\n",
       "       [ 78., 376.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.confusion_matrix(y_test, estimates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
